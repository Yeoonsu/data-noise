{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean train set, clean test set\n",
    "\n",
    "for i in range(0, 1):\n",
    "    # prefix 1~30 까지의 train set을 준비\n",
    "    train_df = pd.read_csv(concat_path + \"\\\\\" + 'clean' +'_ACCEPTED_concat.csv') # change (1)\n",
    "\n",
    "    X_train = train_df.drop('label', axis=1)\n",
    "    X_train = X_train.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))    \n",
    "    y_train = train_df['label']\n",
    "\n",
    "    result_df = pd.DataFrame(columns=['Train 파일 이름', 'Test 파일 이름', 'Model', 'Accuracy Score', 'AUC Score'])\n",
    "\n",
    "    for m in range(1, 31):\n",
    "        df = pd.read_csv(temp_path + '/prefix' + str(m) + '_bpic2012_O_ACCEPTED-COMPLETE_clean.csv') # change (2)\n",
    "\n",
    "        train_file_name = 'clean' + '_ACCEPTED_concat' # change (3)\n",
    "        test_file_name = \"prefix\" + str(m) + \"_\" + 'clean' + '_ACCEPTED' # change (4)\n",
    "\n",
    "        # 각 caseid 별 첫번째 event의 timestamp에 의한 train/test set 구분\n",
    "        # df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df_head = df.groupby('Case').head(1).sort_values(by='Timestamp')\n",
    "\n",
    "        total_rows = len(df_head)\n",
    "        train_length = int(total_rows * 0.8)\n",
    "        train_data = df_head.iloc[:train_length]\n",
    "        test_data = df_head.iloc[train_length:]\n",
    "\n",
    "        encoder_test = Aggregate(case_id_col=['Case'], cat_cols=['Activity', 'label'], boolean=False)\n",
    "        encoder_test_df = encoder_test.fit_transform(df)\n",
    "        encoder_test_df['label'] = encoder_test_df['label_deviant'].apply(lambda x: 0 if x > 0 else 1)\n",
    "        encoder_test_df.drop(['label_deviant', 'label_regular'], axis=1, inplace=True)\n",
    "        encoder_test_df = encoder_test_df.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))    \n",
    "        encoder_test_df['set'] = np.where(encoder_test_df.index.isin(train_data['Case']), 'train', 'test')\n",
    "\n",
    "        train = encoder_test_df[encoder_test_df['set'] == 'train']\n",
    "        test = encoder_test_df[encoder_test_df['set'] == 'test']\n",
    "\n",
    "        X_test = test.drop(['label', 'set'], axis=1)\n",
    "        y_test = test['label']\n",
    "\n",
    "        # X_test의 컬럼명을 X_train의 컬럼명과 동일하게 변경, 단 X_test의 컬럼 수는 2개이고 X_train의 컬럼 수는 32개이므로 나머지 컬럼은 0으로 채움\n",
    "        missing_columns = list(set(X_train.columns) - set(X_test.columns))\n",
    "\n",
    "        # missing_columns\n",
    "        for col in missing_columns:\n",
    "            X_test[col] = 0\n",
    "\n",
    "        # 컬럼을 정렬하여 순서를 맞춤\n",
    "        X_test = X_test[X_train.columns]\n",
    "\n",
    "        models = ['Random Forest', 'XGB']\n",
    "        pipelines = [\n",
    "                Pipeline([('model', RandomForestClassifier())]),\n",
    "            Pipeline([('model', XGBClassifier())]),\n",
    "            Pipeline([('model', RidgeClassifier())])\n",
    "        ]\n",
    "        param_grids = [\n",
    "                {\n",
    "                    'model__n_estimators': [5, 10, 20],\n",
    "                'model__max_depth': [2, 4, 6, None],\n",
    "                'model__min_samples_split': [2, 5, 10],\n",
    "                'model__min_samples_leaf': [1, 2, 4],\n",
    "            },\n",
    "            {\n",
    "                    'model__n_estimators': [5, 10, 20],\n",
    "                'model__max_depth': [2, 4, 6, None],\n",
    "                'model__learning_rate': [0.05, 0.1, 0.3],\n",
    "                'model__min_child_weight': [1, 3, 5]\n",
    "            },\n",
    "        ]\n",
    "        for model, pipeline, param_grid in zip(models, pipelines, param_grids):\n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=2024)\n",
    "            grid_model = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='accuracy')\n",
    "            grid_model.fit(X_train, y_train)\n",
    "            best_model = grid_model.best_estimator_\n",
    "\n",
    "            # 테스트 세트에 모델을 적용하여 예측 수행\n",
    "            y_test_pred = best_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            auc = roc_auc_score(y_test, y_test_pred)\n",
    "            result_df = pd.concat([result_df, pd.DataFrame({'Train 파일 이름': [train_file_name], 'Test 파일 이름': [test_file_name],\n",
    "                                                            'Model': [model], 'Accuracy Score': [accuracy],\n",
    "                                                            'AUC Score': [auc]})], ignore_index=True)\n",
    "            \n",
    "    # 결과 저장\n",
    "    save_path = str(result_path + \"\\\\\" + 'clean' + '_ACCEPTED.xlsx') # change (5)\n",
    "    result_df.to_excel(save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean test set\n",
    "\n",
    "for i in range(0, len(noise_type)):\n",
    "    # prefix 1~30 까지의 train set을 준비\n",
    "    train_df = pd.read_csv(concat_path + \"\\\\\" + noise_type[i] +'_ACCEPTED_concat.csv') # change (1)\n",
    "\n",
    "    X_train = train_df.drop('label', axis=1)\n",
    "    X_train = X_train.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))    \n",
    "    y_train = train_df['label']\n",
    "\n",
    "    result_df = pd.DataFrame(columns=['Train 파일 이름', 'Test 파일 이름', 'Model', 'Accuracy Score', 'AUC Score'])\n",
    "\n",
    "    for m in range(1, 31):\n",
    "        # 각 prefix에 대한 score 결과 구하기\n",
    "        df = pd.read_csv(temp_path + '/prefix' + str(m) + '_bpic2012_O_ACCEPTED-COMPLETE_clean.csv') # change (2)\n",
    "\n",
    "        train_file_name = noise_type[i] + '_ACCEPTED_concat' # change (3)\n",
    "        test_file_name = \"prefix\" + str(m) + \"_\" + noise_type[i] + '_ACCEPTED' # change (4)\n",
    "\n",
    "        # 각 caseid 별 첫번째 event의 timestamp에 의한 train/test set 구분\n",
    "        # df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df_head = df.groupby('Case').head(1).sort_values(by='Timestamp')\n",
    "\n",
    "        total_rows = len(df_head)\n",
    "        train_length = int(total_rows * 0.8)\n",
    "        train_data = df_head.iloc[:train_length]\n",
    "        test_data = df_head.iloc[train_length:]\n",
    "\n",
    "        encoder_test = Aggregate(case_id_col=['Case'], cat_cols=['Activity', 'label'], boolean=False)\n",
    "        encoder_test_df = encoder_test.fit_transform(df)\n",
    "        encoder_test_df['label'] = encoder_test_df['label_deviant'].apply(lambda x: 0 if x > 0 else 1)\n",
    "        encoder_test_df.drop(['label_deviant', 'label_regular'], axis=1, inplace=True)\n",
    "        encoder_test_df = encoder_test_df.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))    \n",
    "        encoder_test_df['set'] = np.where(encoder_test_df.index.isin(train_data['Case']), 'train', 'test')\n",
    "\n",
    "        train = encoder_test_df[encoder_test_df['set'] == 'train']\n",
    "        test = encoder_test_df[encoder_test_df['set'] == 'test']\n",
    "\n",
    "        X_test = test.drop(['label', 'set'], axis=1)\n",
    "        y_test = test['label']\n",
    "\n",
    "        # X_test의 컬럼명을 X_train의 컬럼명과 동일하게 변경, 단 X_test의 컬럼 수는 2개이고 X_train의 컬럼 수는 32개이므로 나머지 컬럼은 0으로 채움\n",
    "        missing_columns = list(set(X_train.columns) - set(X_test.columns))\n",
    "\n",
    "        # missing_columns\n",
    "        for col in missing_columns:\n",
    "            X_test[col] = 0\n",
    "\n",
    "        # 컬럼을 정렬하여 순서를 맞춤\n",
    "        X_test = X_test[X_train.columns]\n",
    "\n",
    "        models = ['Random Forest', 'XGB']\n",
    "        pipelines = [\n",
    "                Pipeline([('model', RandomForestClassifier())]),\n",
    "            Pipeline([('model', XGBClassifier())]),\n",
    "            Pipeline([('model', RidgeClassifier())])\n",
    "        ]\n",
    "        param_grids = [\n",
    "                {\n",
    "                    'model__n_estimators': [5, 10, 20],\n",
    "                'model__max_depth': [2, 4, 6, None],\n",
    "                'model__min_samples_split': [2, 5, 10],\n",
    "                'model__min_samples_leaf': [1, 2, 4],\n",
    "            },\n",
    "            {\n",
    "                    'model__n_estimators': [5, 10, 20],\n",
    "                'model__max_depth': [2, 4, 6, None],\n",
    "                'model__learning_rate': [0.05, 0.1, 0.3],\n",
    "                'model__min_child_weight': [1, 3, 5]\n",
    "            },\n",
    "        ]\n",
    "        for model, pipeline, param_grid in zip(models, pipelines, param_grids):\n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=2024)\n",
    "            grid_model = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='accuracy')\n",
    "            grid_model.fit(X_train, y_train)\n",
    "            best_model = grid_model.best_estimator_\n",
    "            # 테스트 세트에 모델을 적용하여 예측 수행\n",
    "            y_test_pred = best_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            auc = roc_auc_score(y_test, y_test_pred)\n",
    "            result_df = pd.concat([result_df, pd.DataFrame({'Train 파일 이름': [train_file_name], 'Test 파일 이름': [test_file_name],\n",
    "                                                            'Model': [model], 'Accuracy Score': [accuracy],\n",
    "                                                            'AUC Score': [auc]})], ignore_index=True)\n",
    "            \n",
    "    # 결과 저장\n",
    "    save_path = str(result_path + \"\\\\\" + noise_type[i] + '_clean-test-set' + '_ACCEPTED.xlsx') # change (5)\n",
    "    result_df.to_excel(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise test set\n",
    "\n",
    "for i in range(0, len(noise_type)):\n",
    "    # prefix 1~30 까지의 train set을 준비\n",
    "    train_df = pd.read_csv(concat_path + \"\\\\\" + noise_type[i] +'_ACCEPTED_concat.csv') # change (1)\n",
    "\n",
    "    X_train = train_df.drop('label', axis=1)\n",
    "    X_train = X_train.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))    \n",
    "    y_train = train_df['label']\n",
    "\n",
    "    result_df = pd.DataFrame(columns=['Train 파일 이름', 'Test 파일 이름', 'Model', 'Accuracy Score', 'AUC Score'])\n",
    "\n",
    "    for m in range(1, 31):\n",
    "        # 각 prefix에 대한 score 결과 구하기\n",
    "        df = pd.read_csv(temp_path + '/prefix' + str(m) + '_' + noise_type[i] + '_bpic2012_O_ACCEPTED-COMPLETE_clean.csv') # change (2)\n",
    "\n",
    "        train_file_name = noise_type[i] + '_ACCEPTED_concat' # change (3)\n",
    "        test_file_name = \"prefix\" + str(m) + \"_\" + noise_type[i] + '_ACCEPTED' # change (4)\n",
    "\n",
    "        # 각 caseid 별 첫번째 event의 timestamp에 의한 train/test set 구분\n",
    "        # df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df_head = df.groupby('Case').head(1).sort_values(by='Timestamp')\n",
    "\n",
    "        total_rows = len(df_head)\n",
    "        train_length = int(total_rows * 0.8)\n",
    "        train_data = df_head.iloc[:train_length]\n",
    "        test_data = df_head.iloc[train_length:]\n",
    "\n",
    "        encoder_test = Aggregate(case_id_col=['Case'], cat_cols=['Activity', 'label'], boolean=False)\n",
    "        encoder_test_df = encoder_test.fit_transform(df)\n",
    "        encoder_test_df['label'] = encoder_test_df['label_deviant'].apply(lambda x: 0 if x > 0 else 1)\n",
    "        encoder_test_df.drop(['label_deviant', 'label_regular'], axis=1, inplace=True)\n",
    "        encoder_test_df = encoder_test_df.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))    \n",
    "        encoder_test_df['set'] = np.where(encoder_test_df.index.isin(train_data['Case']), 'train', 'test')\n",
    "\n",
    "        train = encoder_test_df[encoder_test_df['set'] == 'train']\n",
    "        test = encoder_test_df[encoder_test_df['set'] == 'test']\n",
    "\n",
    "        X_test = test.drop(['label', 'set'], axis=1)\n",
    "        y_test = test['label']\n",
    "\n",
    "        # X_test의 컬럼명을 X_train의 컬럼명과 동일하게 변경, 단 X_test의 컬럼 수는 2개이고 X_train의 컬럼 수는 32개이므로 나머지 컬럼은 0으로 채움\n",
    "        missing_columns = list(set(X_train.columns) - set(X_test.columns))\n",
    "\n",
    "        # missing_columns\n",
    "        for col in missing_columns:\n",
    "            X_test[col] = 0\n",
    "\n",
    "        # 컬럼을 정렬하여 순서를 맞춤\n",
    "        X_test = X_test[X_train.columns]\n",
    "\n",
    "        models = ['Random Forest', 'XGB']\n",
    "        pipelines = [\n",
    "                Pipeline([('model', RandomForestClassifier())]),\n",
    "            Pipeline([('model', XGBClassifier())])\n",
    "        ]\n",
    "        param_grids = [\n",
    "                {\n",
    "                    'model__n_estimators': [5, 10, 20],\n",
    "                'model__max_depth': [2, 4, 6, None],\n",
    "                'model__min_samples_split': [2, 5, 10],\n",
    "                'model__min_samples_leaf': [1, 2, 4],\n",
    "            },\n",
    "            {\n",
    "                    'model__n_estimators': [5, 10, 20],\n",
    "                'model__max_depth': [2, 4, 6, None],\n",
    "                'model__learning_rate': [0.05, 0.1, 0.3],\n",
    "                'model__min_child_weight': [1, 3, 5]\n",
    "            },\n",
    "        ]\n",
    "        for model, pipeline, param_grid in zip(models, pipelines, param_grids):\n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=2024)\n",
    "            grid_model = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='accuracy')\n",
    "            grid_model.fit(X_train, y_train)\n",
    "            best_model = grid_model.best_estimator_\n",
    "            # 테스트 세트에 모델을 적용하여 예측 수행\n",
    "            y_test_pred = best_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            auc = roc_auc_score(y_test, y_test_pred)\n",
    "            result_df = pd.concat([result_df, pd.DataFrame({'Train 파일 이름': [train_file_name], 'Test 파일 이름': [test_file_name],\n",
    "                                                            'Model': [model], 'Accuracy Score': [accuracy],\n",
    "                                                            'AUC Score': [auc]})], ignore_index=True)\n",
    "            \n",
    "    # 결과 저장\n",
    "    save_path = str(result_path + \"\\\\\" + noise_type[i] + '_noise-test-set' + '_ACCEPTED.xlsx') # change (5)\n",
    "    result_df.to_excel(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 목록 생성\n",
    "file_list = [\n",
    "    \"clean_ACCEPTED.xlsx\",\n",
    "    \"insert0.003_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"insert0.006_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"insert0.009_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"moved0.003_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"moved0.006_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"moved0.009_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"replace0.003_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"replace0.006_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"replace0.009_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"rework0.003_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"rework0.006_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"rework0.009_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"skip0.003_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"skip0.006_clean-test-set_ACCEPTED.xlsx\",\n",
    "    \"skip0.009_clean-test-set_ACCEPTED.xlsx\"\n",
    "]\n",
    "\n",
    "# 모든 파일을 하나의 데이터프레임으로 병합\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(result_path, file_name)  # 파일 경로 생성\n",
    "    df = pd.read_excel(file_path)  # 파일 읽기\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)  # 데이터프레임 병합\n",
    "\n",
    "# 결과 출력\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장 \n",
    "combined_df.to_excel('result/merged_clean-test-set_ACCEPTED.xlsx', index=False) # change name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 파일 목록 생성\n",
    "file_list = [\n",
    "    \"clean_ACCEPTED.xlsx\",\n",
    "    \"insert0.003_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"insert0.006_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"insert0.009_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"moved0.003_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"moved0.006_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"moved0.009_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"replace0.003_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"replace0.006_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"replace0.009_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"rework0.003_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"rework0.006_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"rework0.009_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"skip0.003_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"skip0.006_noise-test-set_ACCEPTED.xlsx\",\n",
    "    \"skip0.009_noise-test-set_ACCEPTED.xlsx\"\n",
    "]\n",
    "\n",
    "# 모든 파일을 하나의 데이터프레임으로 병합\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(result_path, file_name)  # 파일 경로 생성\n",
    "    df = pd.read_excel(file_path)  # 파일 읽기\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)  # 데이터프레임 병합\n",
    "\n",
    "# 결과 출력\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장 \n",
    "combined_df.to_excel('result/merged_noise-test-set_ACCEPTED.xlsx', index=False) # change name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 엑셀 파일에서 데이터 불러오기\n",
    "\n",
    "for m in range(0, 15, 3):\n",
    "    for k in range(2):\n",
    "\n",
    "        data = 'BPIC12_ACCEPTED' # change (1)\n",
    "        ylabel = 'AUC Score' # 'Accuracy Score' or 'AUC Score'\n",
    "         \n",
    "        # a 그래프, clean test set\n",
    "\n",
    "        result_df_a = pd.read_excel('result/merged_clean-test-set_ACCEPTED.xlsx') # change (2)\n",
    "    \n",
    "        # 특정 Train 파일 이름과 Model에 대한 데이터 추출\n",
    "        train_file_a = ['insert0.003', 'insert0.006', 'insert0.009',\n",
    "                    'moved0.003', 'moved0.006', 'moved0.009',\n",
    "                    'replace0.003', 'replace0.006', 'replace0.009',\n",
    "                    'rework0.003', 'rework0.006', 'rework0.009',\n",
    "                    'skip0.003', 'skip0.006', 'skip0.009']\n",
    "        model_a = ['Random Forest', 'XGB']\n",
    "        clean_a = ['clean_ACCEPTED_concat'] # change (3)\n",
    "\n",
    "        subset_df_a = result_df_a[(result_df_a['Train 파일 이름'].str.contains(clean_a[0])) & (result_df_a['Model'] == model_a[k])]\n",
    "        accuracy_scores0_a = subset_df_a[ylabel]\n",
    "        accuracy_scores0_a.index = range(1, len(accuracy_scores0_a) + 1)\n",
    "    \n",
    "        subset_df1_a = result_df_a[(result_df_a['Train 파일 이름'].str.contains(train_file_a[m])) & (result_df_a['Model'] == model_a[k])]\n",
    "        accuracy_scores1_a = subset_df1_a[ylabel]\n",
    "        accuracy_scores1_a.index = range(1, len(accuracy_scores1_a) + 1)\n",
    "    \n",
    "        subset_df2_a = result_df_a[(result_df_a['Train 파일 이름'].str.contains(train_file_a[m+1])) & (result_df_a['Model'] == model_a[k])]\n",
    "        accuracy_scores2_a = subset_df2_a[ylabel]\n",
    "        accuracy_scores2_a.index = range(1, len(accuracy_scores2_a) + 1)\n",
    "    \n",
    "        subset_df3_a = result_df_a[(result_df_a['Train 파일 이름'].str.contains(train_file_a[m+2])) & (result_df_a['Model'] == model_a[k])]\n",
    "        accuracy_scores3_a = subset_df3_a[ylabel]\n",
    "        accuracy_scores3_a.index = range(1, len(accuracy_scores3_a) + 1)\n",
    "    \n",
    "    \n",
    "        # b 그래프, noisy test set\n",
    "    \n",
    "        result_df_b = pd.read_excel('result/merged_noise-test-set_ACCEPTED.xlsx') # change (4)\n",
    "    \n",
    "        # 특정 Train 파일 이름과 Model에 대한 데이터 추출\n",
    "        train_file_b = ['insert0.003', 'insert0.006', 'insert0.009',\n",
    "                    'moved0.003', 'moved0.006', 'moved0.009',\n",
    "                    'replace0.003', 'replace0.006', 'replace0.009',\n",
    "                    'rework0.003', 'rework0.006', 'rework0.009',\n",
    "                    'skip0.003', 'skip0.006', 'skip0.009']\n",
    "        model_b = ['Random Forest', 'XGB']\n",
    "        clean_b = ['clean_ACCEPTED_concat'] # change (5)\n",
    "\n",
    "        subset_df_b = result_df_b[(result_df_b['Train 파일 이름'].str.contains(clean_b[0])) & (result_df_b['Model'] == model_b[k])]\n",
    "        accuracy_scores0_b = subset_df_b[ylabel]\n",
    "        accuracy_scores0_b.index = range(1, len(accuracy_scores0_b) + 1)\n",
    "\n",
    "        subset_df1_b = result_df_b[(result_df_b['Train 파일 이름'].str.contains(train_file_b[m])) & (result_df_b['Model'] == model_b[k])]\n",
    "        accuracy_scores1_b = subset_df1_b[ylabel]\n",
    "        accuracy_scores1_b.index = range(1, len(accuracy_scores1_b) + 1)\n",
    "\n",
    "        subset_df2_b = result_df_b[(result_df_b['Train 파일 이름'].str.contains(train_file_b[m+1])) & (result_df_b['Model'] == model_b[k])]\n",
    "        accuracy_scores2_b = subset_df2_b[ylabel]\n",
    "        accuracy_scores2_b.index = range(1, len(accuracy_scores2_b) + 1)\n",
    "\n",
    "        subset_df3_b = result_df_b[(result_df_b['Train 파일 이름'].str.contains(train_file_b[m+2])) & (result_df_b['Model'] == model_b[k])]\n",
    "        accuracy_scores3_b = subset_df3_b[ylabel]\n",
    "        accuracy_scores3_b.index = range(1, len(accuracy_scores3_b) + 1)\n",
    "\n",
    "\n",
    "        # subplot으로 그래프 그리기\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # 첫 번째 그래프\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(accuracy_scores0_a, label=clean_a[0].split('_')[0])\n",
    "        plt.plot(accuracy_scores1_a, label=train_file_a[m].split('_')[0])\n",
    "        plt.plot(accuracy_scores2_a, label=train_file_a[m+1].split('_')[0])\n",
    "        plt.plot(accuracy_scores3_a, label=train_file_a[m+2].split('_')[0])\n",
    "        plt.xlabel('Prefix length')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.ylim(min(min('accuracy_scores0_a'), min('accuracy_scores0_b')), max(max('accuracy_scores0_a'), max('accuracy_scores0_b')))\n",
    "        plt.yscale('linear')\n",
    "        plt.title('Clean Test Set ' + ylabel + f' for Model: {model_a[k]}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # 두 번째 그래프\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(accuracy_scores0_b, label=clean_b[0].split('_')[0])\n",
    "        plt.plot(accuracy_scores1_b, label=train_file_b[m].split('_')[0])\n",
    "        plt.plot(accuracy_scores2_b, label=train_file_b[m+1].split('_')[0])\n",
    "        plt.plot(accuracy_scores3_b, label=train_file_b[m+2].split('_')[0])\n",
    "        plt.xlabel('Prefix length')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.yscale('linear')\n",
    "        plt.ylim(min(min('accuracy_scores0_a'), min('accuracy_scores0_b')), max(max('accuracy_scores0_a'), max('accuracy_scores0_b')))\n",
    "        plt.title('Noise Test Set ' + ylabel + f' for Model: {model_b[k]}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        # plt.savefig('graph/' + data + '_' + ylabel + '_' + model_a[k] +'_' + train_file_b[m].split('_')[0] + '.png')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
