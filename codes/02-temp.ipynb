{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import re\n",
    "import os\n",
    "import pm4py\n",
    "\n",
    "from Declare4Py.Encodings.Aggregate import Aggregate\n",
    "from Declare4Py.Encodings.IndexBased import IndexBased\n",
    "from Declare4Py.Encodings.Static import Static\n",
    "from Declare4Py.Encodings.PreviousState import PreviousState\n",
    "from Declare4Py.Encodings.LastState import LastState\n",
    "from Declare4Py.Encodings.Ngram import Ngram\n",
    "from Declare4Py.Encodings.Declare import Declare\n",
    "\n",
    "# Assuming that AccuracyScore class and preprocessing function are defined somewhere\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import permutations\n",
    "import json, os\n",
    "from collections import OrderedDict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from Declare4Py.Encodings.Aggregate import Aggregate\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path = os.getcwd()\n",
    "input_path = os.sep.join([str(org_path), \"input\"])\n",
    "output_path = os.sep.join([str(org_path), \"output\"])\n",
    "train_temp = os.sep.join([str(org_path), \"train_temp\"])\n",
    "train_path = os.sep.join([str(org_path), \"train\"])\n",
    "temp_path = os.sep.join([str(org_path), \"temp\"])\n",
    "result_path = os.sep.join([str(org_path), \"result\"])\n",
    "concat_path = os.sep.join([str(org_path), \"concat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp 1~30까지 생성\n",
    "\n",
    "file_list = os.listdir(output_path)\n",
    "csv_list = [s for s in file_list if '.csv' in s]  # change '.csv'\n",
    "print(csv_list) # 먼저 확인하기\n",
    "len(csv_list)\n",
    "\n",
    "# noisy data set에 prefix length를 적용하는 코드, temp가 완성된다.\n",
    "for prefix_length in range(1, 31):\n",
    "    for event_log in csv_list:\n",
    "        df = pd.read_csv(output_path + '\\\\' + event_log) # output path\n",
    "        prefix_df = df.groupby('Case').head(prefix_length)  # prefix\n",
    "        prefix_df.to_csv(temp_path + f'\\\\prefix{prefix_length}_{event_log}', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
